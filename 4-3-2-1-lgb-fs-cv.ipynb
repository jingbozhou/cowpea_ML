{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba80178-8b3e-4948-a850-a2fec33041e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_lgb_rfa_cv_psugar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91c36a-3920-4b91-bed1-6eef23d26db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python\n",
    "import os, pickle, logging, pickle, joblib, sys, warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "from mpire import WorkerPool\n",
    "\n",
    "RAW_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/rawData/\"\n",
    "OUT_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/fs_PSugar/\"\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%m-%d %H:%M:%S',\n",
    "    stream=sys.stderr)\n",
    "\n",
    "def _get_lgb_test_score(indice):\n",
    "    \n",
    "    if isinstance(indice, int):\n",
    "        indice = [indice]\n",
    "    \n",
    "    raw_data = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PSugar.txt\"), sep=\"\\t\", index_col=0)\n",
    "    \n",
    "    feat_col = list(np.array([x for x in raw_data.columns if x.startswith(\"fea_\")])[indice])\n",
    "    \n",
    "    #cat_col_names_raw = [\"heading_stage_d\", \"leaf_blast_rep1\", \"leaf_blast_rep2\", \"leaf_blast_average\", \"GR_D3\", \"GR_D2\", \"GR_D1\"]\n",
    "    #cat_col_names_raw = [\"feat_{}\".format(x) for x in cat_col_names_raw]\n",
    "    #cat_col_names = [i for i in feat_col if i in cat_col_names_raw]\n",
    "    #num_col_names = [i for i in feat_col if (i.startswith(\"feat\")) and (i not in cat_col_names)]\n",
    "    #cat_col_num = []\n",
    "    #for item in cat_col_names:\n",
    "        #cat_col_num.append(feat_col.index(item))\n",
    "\n",
    "    target_col = ['HZ-PSugar']\n",
    "    raw_data = raw_data.dropna(subset=target_col)\n",
    "    \n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True,  random_state=0)\n",
    "    y_test_final, y_pred_final = [], []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(raw_data)):\n",
    "        data_train = raw_data.iloc[train_index].copy()\n",
    "        data_test = raw_data.iloc[test_index].copy()\n",
    "\n",
    "        scale_tool = preprocessing.StandardScaler()\n",
    "        scale_tool.fit(data_train.loc[:, feat_col])\n",
    "        data_train.loc[:, feat_col] = scale_tool.transform(data_train.loc[:, feat_col])\n",
    "        data_test.loc[:, feat_col] = scale_tool.transform(data_test.loc[:, feat_col])\n",
    "\n",
    "        train_sel = data_train.sample(frac=0.8, random_state=0)\n",
    "        val_sel = data_train.drop(train_sel.index).copy()\n",
    "\n",
    "        X_train = train_sel[feat_col].copy()\n",
    "        y_train = train_sel[target_col].values.ravel()\n",
    "\n",
    "        X_val = val_sel[feat_col].copy()\n",
    "        y_val = val_sel[target_col].values.ravel()\n",
    "\n",
    "        X_test = data_test[feat_col].copy()\n",
    "        y_test = data_test[target_col].values.ravel()\n",
    "        \n",
    "        \n",
    "        clf_model = lgb.LGBMRegressor(boosting_type=\"gbdt\", n_estimators=1000, random_state=0, n_jobs=4, num_leaves=5, verbose=-1)\n",
    "\n",
    "        clf_model.fit(X_train, y_train, \n",
    "                      eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                      callbacks=[lgb.log_evaluation(period=10), \n",
    "                                 lgb.early_stopping(stopping_rounds=10)])\n",
    "        \n",
    "        y_pred = clf_model.predict(X_test)\n",
    "\n",
    "        y_test_final.extend(y_test)\n",
    "        y_pred_final.extend(y_pred)\n",
    "\n",
    "    #score_pear = pearsonr(y_test, y_pred)[0]\n",
    "    score_rmse = round(metrics.mean_squared_error(y_test_final, y_pred_final, squared=False), 4)\n",
    "    #score_rmse = metrics.mean_squared_error(y_test_final, y_pred_final, squared=False)\n",
    "    #score_nrmse = round(score_rmse / np.std(y_test), 4)\n",
    "\n",
    "    return score_rmse\n",
    "    #return score_nrmse\n",
    "\n",
    "def add_feature(indices, n_jobs=12):\n",
    "    \n",
    "    raw_data_1 = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PSugar.txt\"), sep=\"\\t\", index_col=0)\n",
    "    feat_col = [x for x in raw_data_1.columns if x.startswith(\"fea_\")]\n",
    "\n",
    "    new_indices = list(set(range(len(feat_col))) - set(indices))\n",
    "    params_list = [[indices + [i]] for i in new_indices]\n",
    "\n",
    "    with WorkerPool(n_jobs=n_jobs) as pool:\n",
    "        scores = pool.map(_get_lgb_test_score, params_list, progress_bar=False)\n",
    "    \n",
    "    #indices.append(new_indices[scores.index(max(scores))])\n",
    "    indices.append(new_indices[scores.index(min(scores))])\n",
    "    return min(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    features=[]\n",
    "    best_score_flag = np.inf\n",
    "    raw_data_2 = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PSugar.txt\"), sep=\"\\t\", index_col=0)\n",
    "    all_features = np.array([x for x in raw_data_2.columns if x.startswith(\"fea_\")])\n",
    "    indices = [list(all_features).index(feature) for feature in features]\n",
    "\n",
    "    logging.info(\"JOB START\")\n",
    "    best_num = 1\n",
    "    for i in range(len(all_features)):\n",
    "        score_tmp = add_feature(indices, n_jobs=12)\n",
    "        feature_order_list = all_features[indices]\n",
    "        if score_tmp < best_score_flag:\n",
    "            best_score_flag = score_tmp\n",
    "            best_features = all_features[indices]\n",
    "            best_num = i + 1\n",
    "    \n",
    "        logging.info(\"Round {}: Score:{}, best score:{}({}), feature list:{}\".format(i+1, score_tmp, \n",
    "                                                                                   best_score_flag, \n",
    "                                                                                     best_num,\n",
    "                                                                                   feature_order_list))\n",
    "        \n",
    "        if (i + 1) - best_num > 50:\n",
    "            break\n",
    "\n",
    "    with open(os.path.join(OUT_PATH, \"lgb_rfa_cv_psugar_rmse\"), \"w\") as feat_f:\n",
    "        for item in best_features:\n",
    "            print(item, file=feat_f)\n",
    "        \n",
    "    logging.info(\"JOB DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec58730-7b1b-4951-a8fe-b1b47bdfddfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e920681-06ff-4772-a5c0-4a3f833f59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_lgb_rfe_cv_psugar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd7f3c-0b13-4fc2-9906-6ffff240a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python\n",
    "import os, pickle, logging, pickle, joblib, sys, warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "RAW_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/rawData/\"\n",
    "OUT_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/fs_PSugar/\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%m-%d %H:%M:%S',\n",
    "    stream=sys.stderr)\n",
    "\n",
    "def getLGBShapLessFeat(feat_col=None):\n",
    "    \n",
    "    raw_data = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PSugar.txt\"), sep=\"\\t\", index_col=0)\n",
    "\n",
    "    target_col = ['HZ-PSugar']\n",
    "    raw_data = raw_data.dropna(subset=target_col)\n",
    "\n",
    "    if feat_col is None:\n",
    "        feat_col = [x for x in raw_data.columns if x.startswith(\"fea_\")]\n",
    "\n",
    "    #cat_col_names_raw = [\"heading_stage_d\", \"leaf_blast_rep1\", \"leaf_blast_rep2\", \"leaf_blast_average\", \"GR_D3\", \"GR_D2\", \"GR_D1\"]\n",
    "    #cat_col_names_raw = [\"feat_{}\".format(x) for x in cat_col_names_raw]\n",
    "    #cat_col_names = [i for i in feat_col if i in cat_col_names_raw]\n",
    "    \n",
    "    #num_col_names = [i for i in feat_col if (i.startswith(\"feat\")) and (i not in cat_col_names)]\n",
    "    #cat_col_num = []\n",
    "    #for item in cat_col_names:\n",
    "        #cat_col_num.append(feat_col.index(item))\n",
    "    \n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True,  random_state=0)\n",
    "    y_test_final, y_pred_final = [], []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(raw_data)):\n",
    "        data_train = raw_data.iloc[train_index].copy()\n",
    "        data_test = raw_data.iloc[test_index].copy()\n",
    "\n",
    "        scale_tool = preprocessing.StandardScaler()\n",
    "        scale_tool.fit(data_train.loc[:, feat_col])\n",
    "        data_train.loc[:, feat_col] = scale_tool.transform(data_train.loc[:, feat_col])\n",
    "        data_test.loc[:, feat_col] = scale_tool.transform(data_test.loc[:, feat_col])\n",
    "\n",
    "        train_sel = data_train.sample(frac=0.8, random_state=0)\n",
    "        val_sel = data_train.drop(train_sel.index).copy()\n",
    "\n",
    "        X_train = train_sel[feat_col].copy()\n",
    "        y_train = train_sel[target_col].values.ravel()\n",
    "\n",
    "        X_val = val_sel[feat_col].copy()\n",
    "        y_val = val_sel[target_col].values.ravel()\n",
    "\n",
    "        X_test = data_test[feat_col].copy()\n",
    "        y_test = data_test[target_col].values.ravel()\n",
    "\n",
    "        clf_model = lgb.LGBMRegressor(boosting_type=\"gbdt\", n_estimators=1000, random_state=0, n_jobs=48, num_leaves=5, verbose=-1)\n",
    "\n",
    "        clf_model.fit(X_train, y_train, \n",
    "                      eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                      callbacks=[lgb.log_evaluation(period=10), \n",
    "                                 lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "        y_pred = clf_model.predict(X_test)\n",
    "\n",
    "        y_test_final.extend(y_test)\n",
    "        y_pred_final.extend(y_pred)\n",
    "\n",
    "        if i == 0:\n",
    "            fs_val_df = pd.DataFrame(clf_model.feature_importances_, index=feat_col)\n",
    "            fs_val_df = fs_val_df.rename(columns={0:i+1})\n",
    "        else:\n",
    "            fs_val_tmp = pd.DataFrame(clf_model.feature_importances_, index=feat_col)\n",
    "            fs_val_tmp = fs_val_tmp.rename(columns={0:i+1})\n",
    "            fs_val_df = pd.concat([fs_val_df, fs_val_tmp], axis=1, sort=False)\n",
    "\n",
    "    #score_pear = pearsonr(y_test, y_pred)[0]\n",
    "    score_rmse = round(metrics.mean_squared_error(y_test_final, y_pred_final, squared=False), 4)\n",
    "    #score_rmse = metrics.mean_squared_error(y_test_final, y_pred_final, squared=False)\n",
    "    #score_nrmse = round(score_rmse / np.std(y_test), 4)\n",
    "    \n",
    "    fs_val_df_mean = fs_val_df.mean(axis=1).to_frame()\n",
    "    fs_val_df_mean = fs_val_df_mean.sort_values(by=[0], ascending=False)\n",
    "    less_import_feat = fs_val_df_mean.index[-1]\n",
    "    return score_rmse, less_import_feat\n",
    "    #return score_nrmse, less_import_feat\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    min_feats = 10\n",
    "    raw_data = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PSugar.txt\"), sep=\"\\t\", index_col=0)\n",
    "\n",
    "    feat_col = [x for x in raw_data.columns if x.startswith(\"fea_\")]\n",
    "    logging.info(\"Run number of features:{}\".format(len(feat_col)))\n",
    "    #auc_mean_flag, test_auc_flag, less_import_feat = getCBShapLessFeat()\n",
    "    #auc_mean, test_auc, less_import_feat = getCBShapLessFeat()\n",
    "    score_rmse, less_import_feat = getLGBShapLessFeat()\n",
    "\n",
    "    test_score_flag = score_rmse\n",
    "    best_round = len(feat_col)\n",
    "    feat_list_best = feat_col.copy()\n",
    "    for num_feats in range(len(feat_col)-1, min_feats-1, -1):\n",
    "        logging.info(\"Round:{}, The less important feature is: {}, test_score:{}, best_score:{}({})\".format(num_feats+1, \n",
    "                                                                                                     less_import_feat,score_rmse, \n",
    "                                                                                                            test_score_flag, best_round))\n",
    "        feat_col.remove(less_import_feat)\n",
    "        score_rmse, less_import_feat = getLGBShapLessFeat(feat_col=feat_col)\n",
    "        if score_rmse < test_score_flag:\n",
    "            test_score_flag = min(score_rmse, test_score_flag)\n",
    "            best_round = num_feats\n",
    "            feat_list_best = feat_col.copy()\n",
    "        \n",
    "        if best_round - num_feats > 100:\n",
    "            break\n",
    "            \n",
    "    logging.info(\"Round:{}, The less important feature is: {}, test_score:{}, best_score:{}({})\".format(num_feats+1, \n",
    "                                                                                                     less_import_feat,score_rmse, \n",
    "                                                                                                            test_score_flag, best_round))\n",
    "    if score_rmse < test_score_flag:\n",
    "        test_score_flag = min(score_rmse, test_score_flag)\n",
    "        feat_list_best = feat_col.copy()\n",
    "\n",
    "    logging.info(\"The number of best features:{}\".format(len(feat_list_best)))\n",
    "    logging.info(\"Best features:{}\".format(feat_list_best))\n",
    "    with open(os.path.join(OUT_PATH, \"lgb_rfe_cv_psugar_rmse\"), \"w\") as feat_f:\n",
    "        for item in feat_list_best:\n",
    "            print(item, file=feat_f)\n",
    "\n",
    "    logging.info(\"JOB DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10253e6c-501c-4fe1-9acd-29cedfcb571d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd61d3-bb82-4a67-be76-ce4738a0486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_jobs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d15b79-85b5-4f32-8d93-52026f8a9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "source /data2/zhoujb/anaconda3/etc/profile.d/conda.sh\n",
    "cd /data2/zhoujb/project/cowpea_project/basedXPXLR/ML/fs_PSugar\n",
    "\n",
    "conda activate PyTorchTabular\n",
    "/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python run_cb_rfa_cv_psugar.py > ./1.log 2>&1 \n",
    "conda deactivate\n",
    "echo \"run_cb_rfa_cv_psugar DONE\"\n",
    "\n",
    "conda activate PyTorchTabular\n",
    "/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python run_lgb_rfa_cv_psugar.py > ./2.log 2>&1 \n",
    "conda deactivate\n",
    "echo \"run_lgb_rfa_cv_psugar DONE\"\n",
    "\n",
    "conda activate PyTorchTabular\n",
    "/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python run_cb_rfe_cv_psugar.py > ./3.log 2>&1 \n",
    "conda deactivate\n",
    "echo \"run_cb_rfe_cv_psugar DONE\"\n",
    "\n",
    "conda activate PyTorchTabular\n",
    "/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python run_lgb_rfe_cv_psugar.py > ./4.log 2>&1 \n",
    "conda deactivate\n",
    "echo \"run_lgb_rfe_cv_psugar DONE\"\n",
    "\n",
    "echo \"ALL DONE\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
