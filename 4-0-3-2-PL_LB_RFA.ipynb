{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f076b6a-5b6e-4f16-9b80-f3e6ff2421da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, logging, pickle, joblib, sys, warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import ensemble, metrics, pipeline, preprocessing, impute, model_selection\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "ML_RAW_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/rawData/\"\n",
    "FS_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/fs_PL/\"\n",
    "TEST_RES_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/tesRes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794bb61a-4ddd-4076-a4aa-a2452c43ecbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228\n",
      "[LightGBM] [Info] Number of data points in the train set: 192, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 42.910401\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 102.482\tvalid_1's l2: 122.35\n",
      "[20]\ttraining's l2: 66.9743\tvalid_1's l2: 89.4419\n",
      "[30]\ttraining's l2: 55.5334\tvalid_1's l2: 82.5561\n",
      "[40]\ttraining's l2: 49.5444\tvalid_1's l2: 82.0045\n",
      "[50]\ttraining's l2: 45.6197\tvalid_1's l2: 79.807\n",
      "[60]\ttraining's l2: 42.4523\tvalid_1's l2: 78.6026\n",
      "[70]\ttraining's l2: 39.7582\tvalid_1's l2: 77.3776\n",
      "[80]\ttraining's l2: 36.7056\tvalid_1's l2: 77.0675\n",
      "[90]\ttraining's l2: 34.0829\tvalid_1's l2: 77.5525\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's l2: 36.2181\tvalid_1's l2: 76.8452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 226\n",
      "[LightGBM] [Info] Number of data points in the train set: 193, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 43.576455\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 87.9868\tvalid_1's l2: 142.757\n",
      "[20]\ttraining's l2: 52.9814\tvalid_1's l2: 115.012\n",
      "[30]\ttraining's l2: 43.1139\tvalid_1's l2: 107.6\n",
      "[40]\ttraining's l2: 38.4031\tvalid_1's l2: 106.605\n",
      "[50]\ttraining's l2: 34.2642\tvalid_1's l2: 102.789\n",
      "[60]\ttraining's l2: 31.8925\tvalid_1's l2: 101.858\n",
      "[70]\ttraining's l2: 29.9441\tvalid_1's l2: 99.9427\n",
      "[80]\ttraining's l2: 28.3056\tvalid_1's l2: 97.7509\n",
      "[90]\ttraining's l2: 26.8491\tvalid_1's l2: 98.1493\n",
      "[100]\ttraining's l2: 25.5361\tvalid_1's l2: 97.0108\n",
      "[110]\ttraining's l2: 24.273\tvalid_1's l2: 96.9449\n",
      "[120]\ttraining's l2: 23.2053\tvalid_1's l2: 96.3516\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's l2: 23.7148\tvalid_1's l2: 95.8952\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 227\n",
      "[LightGBM] [Info] Number of data points in the train set: 193, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 42.534779\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 89.0948\tvalid_1's l2: 160.015\n",
      "[20]\ttraining's l2: 57.6839\tvalid_1's l2: 116.613\n",
      "[30]\ttraining's l2: 47.9197\tvalid_1's l2: 107.245\n",
      "[40]\ttraining's l2: 42.1503\tvalid_1's l2: 97.0147\n",
      "[50]\ttraining's l2: 38.2803\tvalid_1's l2: 94.2948\n",
      "[60]\ttraining's l2: 35.5477\tvalid_1's l2: 92.6232\n",
      "[70]\ttraining's l2: 33.1256\tvalid_1's l2: 90.1466\n",
      "[80]\ttraining's l2: 30.9954\tvalid_1's l2: 89.6876\n",
      "[90]\ttraining's l2: 29.0674\tvalid_1's l2: 87.8419\n",
      "[100]\ttraining's l2: 27.2359\tvalid_1's l2: 87.0554\n",
      "[110]\ttraining's l2: 25.5636\tvalid_1's l2: 86.4318\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's l2: 25.7306\tvalid_1's l2: 86.1166\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 244\n",
      "[LightGBM] [Info] Number of data points in the train set: 193, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 43.222765\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 107.056\tvalid_1's l2: 154.49\n",
      "[20]\ttraining's l2: 69.1649\tvalid_1's l2: 110.87\n",
      "[30]\ttraining's l2: 56.3058\tvalid_1's l2: 96.1248\n",
      "[40]\ttraining's l2: 49.5833\tvalid_1's l2: 88.3222\n",
      "[50]\ttraining's l2: 45.0262\tvalid_1's l2: 85.2181\n",
      "[60]\ttraining's l2: 41.8506\tvalid_1's l2: 83.669\n",
      "[70]\ttraining's l2: 39.2962\tvalid_1's l2: 81.7231\n",
      "[80]\ttraining's l2: 37.0874\tvalid_1's l2: 80.7365\n",
      "[90]\ttraining's l2: 34.8065\tvalid_1's l2: 78.1154\n",
      "[100]\ttraining's l2: 33.0612\tvalid_1's l2: 77.9974\n",
      "[110]\ttraining's l2: 31.4869\tvalid_1's l2: 76.3276\n",
      "[120]\ttraining's l2: 30.127\tvalid_1's l2: 75.6663\n",
      "[130]\ttraining's l2: 28.6322\tvalid_1's l2: 75.2118\n",
      "[140]\ttraining's l2: 27.394\tvalid_1's l2: 74.3839\n",
      "[150]\ttraining's l2: 26.2913\tvalid_1's l2: 73.6263\n",
      "[160]\ttraining's l2: 25.1673\tvalid_1's l2: 74.1259\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's l2: 26.1348\tvalid_1's l2: 73.5408\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 218\n",
      "[LightGBM] [Info] Number of data points in the train set: 193, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 43.033724\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 104.464\tvalid_1's l2: 113.899\n",
      "[20]\ttraining's l2: 62.5198\tvalid_1's l2: 85.186\n",
      "[30]\ttraining's l2: 50.1851\tvalid_1's l2: 76.9949\n",
      "[40]\ttraining's l2: 43.9034\tvalid_1's l2: 73.8445\n",
      "[50]\ttraining's l2: 39.7129\tvalid_1's l2: 70.7696\n",
      "[60]\ttraining's l2: 36.3898\tvalid_1's l2: 69.9462\n",
      "[70]\ttraining's l2: 33.7337\tvalid_1's l2: 69.8073\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's l2: 34.2249\tvalid_1's l2: 68.8952\n"
     ]
    }
   ],
   "source": [
    "feat_col = []\n",
    "with open(os.path.join(FS_PATH, \"lgb_rfa_cv_pl_rmse\")) as f:\n",
    "    for line in f:\n",
    "        feat_col.append(line.strip())\n",
    "\n",
    "raw_data = pd.read_table(os.path.join(ML_RAW_PATH, \"raw_data_PL.txt\"), sep=\"\\t\", index_col=0)\n",
    "\n",
    "target_col = ['HZ-PL']\n",
    "raw_data = raw_data.dropna(subset=target_col)\n",
    "\n",
    "#cat_col_names_raw = [\"heading_stage_d\", \"leaf_blast_rep1\", \"leaf_blast_rep2\", \"leaf_blast_average\", \"GR_D3\", \"GR_D2\", \"GR_D1\"]\n",
    "#cat_col_names_raw = [\"feat_{}\".format(x) for x in cat_col_names_raw]\n",
    "#cat_col_names = [i for i in feat_col if i in cat_col_names_raw]\n",
    "#num_col_names = [i for i in feat_col if (i.startswith(\"feat\")) and (i not in cat_col_names)]\n",
    "#cat_col_num = []\n",
    "#for item in cat_col_names:\n",
    "    #cat_col_num.append(feat_col.index(item))\n",
    "\n",
    "#for col in cat_col_names:\n",
    "    #raw_data[col] = raw_data[col].astype(\"str\")\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True,  random_state=0)\n",
    "y_test_final, y_pred_final = [], []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(raw_data)):\n",
    "    data_train = raw_data.iloc[train_index].copy()\n",
    "    data_test = raw_data.iloc[test_index].copy()\n",
    "    \n",
    "    scale_tool = preprocessing.StandardScaler()\n",
    "    scale_tool.fit(data_train.loc[:, feat_col])\n",
    "    data_train.loc[:, feat_col] = scale_tool.transform(data_train.loc[:, feat_col])\n",
    "    data_test.loc[:, feat_col] = scale_tool.transform(data_test.loc[:, feat_col])\n",
    "\n",
    "    train_sel = data_train.sample(frac=0.8, random_state=0)\n",
    "    val_sel = data_train.drop(train_sel.index).copy()\n",
    "\n",
    "    X_train = train_sel[feat_col].copy()\n",
    "    y_train = train_sel[target_col].values.ravel()\n",
    "\n",
    "    X_val = val_sel[feat_col].copy()\n",
    "    y_val = val_sel[target_col].values.ravel()\n",
    "\n",
    "    X_test = data_test[feat_col].copy()\n",
    "    y_test = data_test[target_col].values.ravel()\n",
    "\n",
    "    # Initialize CatBoostClassifier\n",
    "    clf_model = lgb.LGBMRegressor(boosting_type=\"gbdt\", n_estimators=1000, random_state=0, n_jobs=4, num_leaves=5)\n",
    "\n",
    "    clf_model.fit(X_train, y_train, \n",
    "                  eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                  callbacks=[lgb.log_evaluation(period=10), \n",
    "                             lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "\n",
    "    y_test_final.append(y_test)\n",
    "    y_pred_final.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236b289-d6bc-4d80-8784-14b86ae35a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19759be1-fb0d-4a4e-a447-c934db93b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns=[\"Model\", \"Times\", \"Score\", \"Type\"])\n",
    "for i in range(len(y_test_final)):\n",
    "    ## Get score\n",
    "    #score_pear = pearsonr(y_test_final[i], y_pred_final[i])[0]\n",
    "    score_spear = spearmanr(y_test_final[i], y_pred_final[i])[0]\n",
    "    #score_rmse = metrics.mean_squared_error(y_test_final[i], y_pred_final[i], squared=False)\n",
    "    score_rmse = metrics.root_mean_squared_error(y_test_final[i], y_pred_final[i])\n",
    "    score_nrmse = score_rmse / np.std(y_test_final[i])\n",
    "\n",
    "    #res_df.loc[len(res_df)] = [\"LB_RFA\", i+1, score_pear, \"R\"]\n",
    "    res_df.loc[len(res_df)] = [\"LB_RFA\", i+1, score_spear, \"R\"]\n",
    "    res_df.loc[len(res_df)] = [\"LB_RFA\", i+1, score_rmse, \"RMSE\"]\n",
    "    res_df.loc[len(res_df)] = [\"LB_RFA\", i+1, score_nrmse, \"NRMSE\"]\n",
    "\n",
    "with open(os.path.join(TEST_RES_PATH, \"PL_LB_RFA.pickle\"), \"wb\") as out_f:\n",
    "    pickle.dump(res_df, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566c77fc-fa8e-4c03-8ad1-d5a0e1622afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "NRMSE    0.478180\n",
       "R        0.862490\n",
       "RMSE     7.805086\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.groupby([\"Type\"])[\"Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ac8d5-ed16-40c9-b932-7a6fc545d910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d168dfd6-d7a1-46dd-956c-bacf4881d38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Times</th>\n",
       "      <th>Score</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904466</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>1</td>\n",
       "      <td>6.707625</td>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403047</td>\n",
       "      <td>NRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>2</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>2</td>\n",
       "      <td>8.409943</td>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471744</td>\n",
       "      <td>NRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>3</td>\n",
       "      <td>0.906153</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>3</td>\n",
       "      <td>7.686936</td>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>3</td>\n",
       "      <td>0.472184</td>\n",
       "      <td>NRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>4</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>4</td>\n",
       "      <td>7.637079</td>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>4</td>\n",
       "      <td>0.495949</td>\n",
       "      <td>NRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>5</td>\n",
       "      <td>7.875939</td>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LB_RFA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.526950</td>\n",
       "      <td>NRMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Times     Score   Type\n",
       "0   LB_RFA      1  0.904466      R\n",
       "1   LB_RFA      1  6.707625   RMSE\n",
       "2   LB_RFA      1  0.403047  NRMSE\n",
       "3   LB_RFA      2  0.869893      R\n",
       "4   LB_RFA      2  8.409943   RMSE\n",
       "5   LB_RFA      2  0.471744  NRMSE\n",
       "6   LB_RFA      3  0.906153      R\n",
       "7   LB_RFA      3  7.686936   RMSE\n",
       "8   LB_RFA      3  0.472184  NRMSE\n",
       "9   LB_RFA      4  0.804612      R\n",
       "10  LB_RFA      4  7.637079   RMSE\n",
       "11  LB_RFA      4  0.495949  NRMSE\n",
       "12  LB_RFA      5  0.823284      R\n",
       "13  LB_RFA      5  7.875939   RMSE\n",
       "14  LB_RFA      5  0.526950  NRMSE"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(TEST_RES_PATH, \"PL_LB_RFA.pickle\"), \"rb\") as f:\n",
    "    res_df = pickle.load(f)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9098e2f2-9c91-4c85-91f7-f72042ed51c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "NRMSE    0.473975\n",
       "R        0.861682\n",
       "RMSE     7.663504\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.groupby([\"Type\"])[\"Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea116ba-f508-4540-9726-2c24aceb937e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
