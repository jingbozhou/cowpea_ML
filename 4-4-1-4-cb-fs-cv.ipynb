{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7385d6-2a85-4c86-9036-f5e6d25830d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_cb_rfa_cv_pstarch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346f907-b5f0-4ca3-be19-f6b3b32f25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python\n",
    "import os, pickle, logging, pickle, joblib, sys, warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "from mpire import WorkerPool\n",
    "\n",
    "RAW_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/rawData/\"\n",
    "OUT_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/fs_PStarch/\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%m-%d %H:%M:%S',\n",
    "    stream=sys.stderr)\n",
    "\n",
    "def _get_cb_test_score(indice):\n",
    "\n",
    "    if isinstance(indice, int):\n",
    "        indice = [indice]\n",
    "    \n",
    "    raw_data = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PStarch.txt\"), sep=\"\\t\", index_col=0)\n",
    "    \n",
    "    feat_col = list(np.array([x for x in raw_data.columns if x.startswith(\"fea_\")])[indice])\n",
    "    \n",
    "    #cat_col_names_raw = [\"heading_stage_d\", \"leaf_blast_rep1\", \"leaf_blast_rep2\", \"leaf_blast_average\", \"GR_D3\", \"GR_D2\", \"GR_D1\"]\n",
    "    #cat_col_names_raw = [\"feat_{}\".format(x) for x in cat_col_names_raw]\n",
    "    #cat_col_names = [i for i in feat_col if i in cat_col_names_raw]\n",
    "    #num_col_names = [i for i in feat_col if (i.startswith(\"feat\")) and (i not in cat_col_names)]\n",
    "    #cat_col_num = []\n",
    "    #for item in cat_col_names:\n",
    "        #cat_col_num.append(feat_col.index(item))\n",
    "\n",
    "    #for col in cat_col_names:\n",
    "        #raw_data[col] = raw_data[col].astype(\"str\")\n",
    "\n",
    "    target_col = ['HZ-PStarch']\n",
    "    raw_data = raw_data.dropna(subset=target_col)\n",
    "    \n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True,  random_state=0)\n",
    "    y_test_final, y_pred_final = [], []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(raw_data)):\n",
    "        data_train = raw_data.iloc[train_index].copy()\n",
    "        data_test = raw_data.iloc[test_index].copy()\n",
    "\n",
    "        scale_tool = preprocessing.StandardScaler()\n",
    "        scale_tool.fit(data_train.loc[:, feat_col])\n",
    "        data_train.loc[:, feat_col] = scale_tool.transform(data_train.loc[:, feat_col])\n",
    "        data_test.loc[:, feat_col] = scale_tool.transform(data_test.loc[:, feat_col])\n",
    "\n",
    "        train_sel = data_train.sample(frac=0.8, random_state=0)\n",
    "        val_sel = data_train.drop(train_sel.index).copy()\n",
    "\n",
    "        X_train = train_sel[feat_col].copy()\n",
    "        y_train = train_sel[target_col].values.ravel()\n",
    "\n",
    "        X_val = val_sel[feat_col].copy()\n",
    "        y_val = val_sel[target_col].values.ravel()\n",
    "\n",
    "        X_test = data_test[feat_col].copy()\n",
    "        y_test = data_test[target_col].values.ravel()\n",
    "        \n",
    "        \n",
    "        # Initialize CatBoostClassifier\n",
    "        clf_model = cb.CatBoostRegressor(random_state=0, thread_count=4, loss_function='RMSE', verbose=0)\n",
    "        \n",
    "        # Fit model\n",
    "        clf_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], verbose=0, plot=False)\n",
    "        \n",
    "        y_pred = clf_model.predict(X_test)\n",
    "\n",
    "        y_test_final.extend(y_test)\n",
    "        y_pred_final.extend(y_pred)\n",
    "\n",
    "    #score_pear = pearsonr(y_test, y_pred)[0]\n",
    "    score_rmse = round(metrics.mean_squared_error(y_test_final, y_pred_final, squared=False), 4)\n",
    "    #score_rmse = metrics.mean_squared_error(y_test_final, y_pred_final, squared=False)\n",
    "    #score_nrmse = round(score_rmse / np.std(y_test), 4)\n",
    "\n",
    "    return score_rmse\n",
    "    #return score_nrmse\n",
    "\n",
    "def add_feature(indices, n_jobs=12):\n",
    "    \n",
    "    raw_data_1 = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PStarch.txt\"), sep=\"\\t\", index_col=0)\n",
    "    feat_col = [x for x in raw_data_1.columns if x.startswith(\"fea_\")]\n",
    "\n",
    "    new_indices = list(set(range(len(feat_col))) - set(indices))\n",
    "    params_list = [[indices + [i]] for i in new_indices]\n",
    "\n",
    "    with WorkerPool(n_jobs=n_jobs) as pool:\n",
    "        scores = pool.map(_get_cb_test_score, params_list, progress_bar=False)\n",
    "    \n",
    "    #indices.append(new_indices[scores.index(max(scores))])\n",
    "    indices.append(new_indices[scores.index(min(scores))])\n",
    "    return min(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    features=[]\n",
    "    best_score_flag = np.inf\n",
    "    raw_data_2 = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PStarch.txt\"), sep=\"\\t\", index_col=0)\n",
    "    all_features = np.array([x for x in raw_data_2.columns if x.startswith(\"fea_\")])\n",
    "    indices = [list(all_features).index(feature) for feature in features]\n",
    "\n",
    "    best_num = 1\n",
    "    for i in range(len(all_features)):\n",
    "        score_tmp = add_feature(indices, n_jobs=12)\n",
    "        feature_order_list = all_features[indices]\n",
    "        if score_tmp < best_score_flag:\n",
    "            best_score_flag = score_tmp\n",
    "            best_features = all_features[indices]\n",
    "            best_num = i + 1\n",
    "    \n",
    "        logging.info(\"Round {}: Score:{}, best score:{}({}), feature list:{}\".format(i+1, score_tmp, \n",
    "                                                                                   best_score_flag, \n",
    "                                                                                     best_num,\n",
    "                                                                                   feature_order_list))\n",
    "        \n",
    "        if (i + 1) - best_num > 50:\n",
    "            break\n",
    "\n",
    "    with open(os.path.join(OUT_PATH, \"cb_rfa_cv_pstarch_rmse\"), \"w\") as feat_f:\n",
    "        for item in best_features:\n",
    "            print(item, file=feat_f)\n",
    "        \n",
    "    logging.info(\"JOB DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5005554-0bf0-4d37-9b33-9f06fe33e571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bca0a1-813d-45d3-b9dd-b11ca2bee928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_cb_rfe_cv_pstarch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83504c94-719d-4284-bfe4-abbf92aba2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/data2/zhoujb/anaconda3/envs/PyTorchTabular/bin/python\n",
    "import os, pickle, logging, pickle, joblib, sys, warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "RAW_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/rawData/\"\n",
    "OUT_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/ML/fs_PStarch/\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%m-%d %H:%M:%S',\n",
    "    stream=sys.stderr)\n",
    "\n",
    "def getCBShapLessFeat(feat_col=None):\n",
    "    \n",
    "    raw_data = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PStarch.txt\"), sep=\"\\t\", index_col=0)\n",
    "\n",
    "    target_col = ['HZ-PStarch']\n",
    "    raw_data = raw_data.dropna(subset=target_col)\n",
    "\n",
    "    if feat_col is None:\n",
    "        feat_col = [x for x in raw_data.columns if x.startswith(\"fea_\")]\n",
    "\n",
    "    #cat_col_names_raw = [\"heading_stage_d\", \"leaf_blast_rep1\", \"leaf_blast_rep2\", \"leaf_blast_average\", \"GR_D3\", \"GR_D2\", \"GR_D1\"]\n",
    "    #cat_col_names_raw = [\"feat_{}\".format(x) for x in cat_col_names_raw]\n",
    "    #cat_col_names = [i for i in feat_col if i in cat_col_names_raw]\n",
    "    \n",
    "    #num_col_names = [i for i in feat_col if (i.startswith(\"feat\")) and (i not in cat_col_names)]\n",
    "    #cat_col_num = []\n",
    "    #for item in cat_col_names:\n",
    "        #cat_col_num.append(feat_col.index(item))\n",
    "\n",
    "    #for col in cat_col_names:\n",
    "        #raw_data[col] = raw_data[col].astype(\"str\")\n",
    "\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True,  random_state=0)\n",
    "    y_test_final, y_pred_final = [], []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(raw_data)):\n",
    "        data_train = raw_data.iloc[train_index].copy()\n",
    "        data_test = raw_data.iloc[test_index].copy()\n",
    "\n",
    "        scale_tool = preprocessing.StandardScaler()\n",
    "        scale_tool.fit(data_train.loc[:, feat_col])\n",
    "        data_train.loc[:, feat_col] = scale_tool.transform(data_train.loc[:, feat_col])\n",
    "        data_test.loc[:, feat_col] = scale_tool.transform(data_test.loc[:, feat_col])\n",
    "\n",
    "        train_sel = data_train.sample(frac=0.8, random_state=0)\n",
    "        val_sel = data_train.drop(train_sel.index).copy()\n",
    "\n",
    "        X_train = train_sel[feat_col].copy()\n",
    "        y_train = train_sel[target_col].values.ravel()\n",
    "\n",
    "        X_val = val_sel[feat_col].copy()\n",
    "        y_val = val_sel[target_col].values.ravel()\n",
    "\n",
    "        X_test = data_test[feat_col].copy()\n",
    "        y_test = data_test[target_col].values.ravel()\n",
    "\n",
    "        # Initialize CatBoostClassifier\n",
    "        clf_model = cb.CatBoostRegressor(random_state=0, thread_count=48, loss_function='RMSE', verbose=0)\n",
    "\n",
    "        # Fit model\n",
    "        clf_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], verbose=0, plot=False)\n",
    "\n",
    "        y_pred = clf_model.predict(X_test)\n",
    "\n",
    "        y_test_final.extend(y_test)\n",
    "        y_pred_final.extend(y_pred)\n",
    "\n",
    "        if i == 0:\n",
    "            fs_val_df = pd.DataFrame(clf_model.feature_importances_, index=feat_col)\n",
    "            fs_val_df = fs_val_df.rename(columns={0:i+1})\n",
    "        else:\n",
    "            fs_val_tmp = pd.DataFrame(clf_model.feature_importances_, index=feat_col)\n",
    "            fs_val_tmp = fs_val_tmp.rename(columns={0:i+1})\n",
    "            fs_val_df = pd.concat([fs_val_df, fs_val_tmp], axis=1, sort=False)\n",
    "\n",
    "    #score_pear = pearsonr(y_test, y_pred)[0]\n",
    "    score_rmse = round(metrics.mean_squared_error(y_test_final, y_pred_final, squared=False), 4)\n",
    "    #score_rmse = metrics.mean_squared_error(y_test_final, y_pred_final, squared=False)\n",
    "    #score_nrmse = round(score_rmse / np.std(y_test), 4)\n",
    "    \n",
    "    fs_val_df_mean = fs_val_df.mean(axis=1).to_frame()\n",
    "    fs_val_df_mean = fs_val_df_mean.sort_values(by=[0], ascending=False)\n",
    "    less_import_feat = fs_val_df_mean.index[-1]\n",
    "    return score_rmse, less_import_feat\n",
    "    #return score_nrmse, less_import_feat\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    min_feats = 10\n",
    "    raw_data = pd.read_table(os.path.join(RAW_PATH, \"raw_data_PStarch.txt\"), sep=\"\\t\", index_col=0)\n",
    "\n",
    "    feat_col = [x for x in raw_data.columns if x.startswith(\"fea_\")]\n",
    "    logging.info(\"Run number of features:{}\".format(len(feat_col)))\n",
    "    #auc_mean_flag, test_auc_flag, less_import_feat = getCBShapLessFeat()\n",
    "    #auc_mean, test_auc, less_import_feat = getCBShapLessFeat()\n",
    "    score_rmse, less_import_feat = getCBShapLessFeat()\n",
    "\n",
    "    test_score_flag = score_rmse\n",
    "    best_round = len(feat_col)\n",
    "    feat_list_best = feat_col.copy()\n",
    "    for num_feats in range(len(feat_col)-1, min_feats-1, -1):\n",
    "        logging.info(\"Round:{}, The less important feature is: {}, test_score:{}, best_score:{}({})\".format(num_feats+1, \n",
    "                                                                                                     less_import_feat,score_rmse, \n",
    "                                                                                                            test_score_flag, best_round))\n",
    "        feat_col.remove(less_import_feat)\n",
    "        score_rmse, less_import_feat = getCBShapLessFeat(feat_col=feat_col)\n",
    "        if score_rmse < test_score_flag:\n",
    "            test_score_flag = min(score_rmse, test_score_flag)\n",
    "            best_round = num_feats\n",
    "            feat_list_best = feat_col.copy()\n",
    "        \n",
    "        if best_round - num_feats > 100:\n",
    "            break\n",
    "            \n",
    "    logging.info(\"Round:{}, The less important feature is: {}, test_score:{}, best_score:{}({})\".format(num_feats+1, \n",
    "                                                                                                     less_import_feat,score_rmse, \n",
    "                                                                                                            test_score_flag, best_round))\n",
    "    if score_rmse < test_score_flag:\n",
    "        test_score_flag = min(score_rmse, test_score_flag)\n",
    "        feat_list_best = feat_col.copy()\n",
    "\n",
    "    logging.info(\"The number of best features:{}\".format(len(feat_list_best)))\n",
    "    logging.info(\"Best features:{}\".format(feat_list_best))\n",
    "    with open(os.path.join(OUT_PATH, \"cb_rfe_cv_pstarch_rmse\"), \"w\") as feat_f:\n",
    "        for item in feat_list_best:\n",
    "            print(item, file=feat_f)\n",
    "\n",
    "    logging.info(\"JOB DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
