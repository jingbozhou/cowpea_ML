{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f65d9aa-a947-4e73-82f6-455e0fad102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "region_name = \"Chr07_6770001_6920000\"\n",
    "SNP_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/snpDir/\"\n",
    "RAW_PATH = \"/data2/zhoujb/project/cowpea_project/rawData/\"\n",
    "RES_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/Result/\"\n",
    "OUT_PATH = \"/data2/zhoujb/project/cowpea_project/basedXPXLR/GWAS/PL/{}/\".format(region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f32b491-ff77-4a9a-bb68-6a974b296a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF file saved as /data2/zhoujb/project/cowpea_project/basedXPXLR/GWAS/PL/Chr07_6770001_6920000/Chr07_6770001_6920000.vcf\n",
      "ALL DONE\n"
     ]
    }
   ],
   "source": [
    "# 表型数据\n",
    "raw_phenos = pd.read_excel(os.path.join(RAW_PATH, \"Phenotypes for GWAS-upload public database.xlsx\"), index_col=\"Accessions\")\n",
    "raw_phenos = raw_phenos.drop(columns=\"ID\")\n",
    "raw_phenos = raw_phenos.replace({\"-\":np.nan})\n",
    "raw_phenos = raw_phenos.dropna(axis=0, how=\"all\")\n",
    "raw_phenos = raw_phenos.rename(columns={'HZ-Pod length':'HZ-PL', 'GZ-Pod length':'GZ-PL', \n",
    "                                        'HZ Pod Sugar content (mg/g)':'HZ-PSugar','GZ Pod Sugar content  (mg/g)':'GZ-PSugar', \n",
    "                                        'HZ Pod Starch content(mg/g)':'HZ-PStarch','GZ Pod Strach Content (mg/g)':'GZ-PStarch', \n",
    "                                        'HZ Pod Protein content(g/Kg)':'HZ-PProtein','GZ Pod protein  (g/Kg)':'GZ-PProtein', \n",
    "                                        'HZ Seed Sugar (mg/g)':'HZ-SSuger','GZ Seed Sugar (mg/g)':'GZ-SSuger', \n",
    "                                        'HZ Seed Starch (mg/g)':'HZ-SStarch','GZ Seed Starch (mg/g)':'GZ-SStarch', \n",
    "                                        'HZ Seed Protein (g/kg)':'HZ-SProtein','GZ Seed Protein (g/kg)':'GZ-SProtein', \n",
    "                                        'Pod shattering':'PS'})\n",
    "target_df = raw_phenos[[\"HZ-PL\"]].dropna()\n",
    "\n",
    "acc_list = target_df.index.to_list()\n",
    "\n",
    "#基因型数据\n",
    "raw_snp = pd.read_table(os.path.join(SNP_PATH, \"{}.txt\".format(region_name)))\n",
    "#raw_snp = raw_snp.fillna(\"N\")\n",
    "#raw_snp = raw_snp.replace({'Y':\"N\", 'R':\"N\", 'S':\"N\", 'W':\"N\", 'M':\"N\", 'K':\"N\"})\n",
    "\n",
    "acc_inte = list(set(acc_list).intersection(raw_snp.columns))\n",
    "\n",
    "target_df = target_df.loc[acc_inte]\n",
    "raw_snp = raw_snp[['Chr', 'Pos']+acc_inte]\n",
    "\n",
    "# Mapping IUPAC codes to possible alleles\n",
    "iupac_to_alleles = {\n",
    "    'A': ['A'],\n",
    "    'T': ['T'],\n",
    "    'C': ['C'],\n",
    "    'G': ['G'],\n",
    "    'R': ['A', 'G'],\n",
    "    'Y': ['C', 'T'],\n",
    "    'M': ['A', 'C'],\n",
    "    'K': ['G', 'T'],\n",
    "    'S': ['G', 'C'],\n",
    "    'W': ['A', 'T'],\n",
    "    'H': ['A', 'T', 'C'],\n",
    "    'B': [ 'T', 'C', 'G'],\n",
    "    'V': ['A', 'C', 'G'],\n",
    "    'D': ['A', 'T', 'G'],\n",
    "    'N': ['A', 'T', 'C', 'G']\n",
    "}\n",
    "\n",
    "def convert_iupac_to_alleles(iupac_code):\n",
    "    return iupac_to_alleles.get(iupac_code, ['N'])\n",
    "\n",
    "def most_frequent_values(input_list):\n",
    "    # Count occurrences of each element\n",
    "    counts = Counter(input_list)\n",
    "    \n",
    "    # Find the maximum frequency\n",
    "    max_count = max(counts.values())\n",
    "    \n",
    "    # Find all elements with the maximum frequency\n",
    "    most_frequent = [item for item, count in counts.items() if count == max_count]\n",
    "    \n",
    "    return most_frequent[0]\n",
    "\n",
    "# Create VCF header\n",
    "vcf_header = [\n",
    "    '##fileformat=VCFv4.2',\n",
    "    '##source=custom_script',\n",
    "    '##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">',\n",
    "    #'#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\t' + '\\t'.join([\"{}_{}\".format(x, x) for x in acc_inte])\n",
    "    '#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\t' + '\\t'.join(acc_inte)\n",
    "]\n",
    "\n",
    "# Create a list to store VCF data lines\n",
    "vcf_lines = []\n",
    "# Iterate through each SNP (row in the original table)\n",
    "for index in raw_snp.index:\n",
    "    row_values = raw_snp.loc[index].values\n",
    "    chrom = str(int(row_values[0][-2:]))\n",
    "    pos = str(row_values[1])\n",
    "    snp_id = str(row_values[1])\n",
    "    \n",
    "    # Collect unique alleles\n",
    "    alleles_list = []\n",
    "    for val in row_values[2:]:\n",
    "        if val == \"N\":\n",
    "            continue\n",
    "    \n",
    "        alleles = convert_iupac_to_alleles(val)\n",
    "        alleles_list.extend(alleles)\n",
    "\n",
    "    most_freq_val = most_frequent_values(alleles_list)\n",
    "    ref = most_freq_val\n",
    "\n",
    "    alleles_list = list(set(alleles_list))\n",
    "    alleles_list.remove(ref)\n",
    "    alt = ','.join(alleles_list)\n",
    "        \n",
    "    # Generate the genotype data for each sample\n",
    "    genotypes = []\n",
    "    for val in row_values[2:]:\n",
    "        if val == 'N':\n",
    "            genotypes.append('./.')\n",
    "        else:\n",
    "            alleles = convert_iupac_to_alleles(val)\n",
    "            if len(alleles) > 1:\n",
    "                if ref in alleles:\n",
    "                     genotypes.append('0/1')\n",
    "                else:\n",
    "                    genotypes.append('1/2')\n",
    "            else:\n",
    "                if alleles[0] == ref:\n",
    "                    genotypes.append('0/0')\n",
    "                elif alleles[0] == alt:\n",
    "                    genotypes.append('1/1')\n",
    "                else:\n",
    "                    genotypes.append('0/1')\n",
    "\n",
    "    # Create the VCF line\n",
    "    qual = '.'\n",
    "    filter = 'PASS'\n",
    "    info = '.'\n",
    "    format_field = 'GT'\n",
    "    vcf_line = f\"{chrom}\\t{pos}\\t{snp_id}\\t{ref}\\t{alt}\\t{qual}\\t{filter}\\t{info}\\t{format_field}\\t\" + '\\t'.join(genotypes)\n",
    "    vcf_lines.append(vcf_line)\n",
    "\n",
    "# Write VCF file\n",
    "output_vcf_file = os.path.join(OUT_PATH, \"{}.vcf\".format(region_name))\n",
    "with open(output_vcf_file, 'w') as vcf_file:\n",
    "    for header_line in vcf_header:\n",
    "        vcf_file.write(header_line + '\\n')\n",
    "    for vcf_line in vcf_lines:\n",
    "        vcf_file.write(vcf_line + '\\n')\n",
    "\n",
    "print(f\"VCF file saved as {output_vcf_file}\")\n",
    "\n",
    "with open(os.path.join(OUT_PATH, \"PL.txt\"), \"w\") as phen_file:\n",
    "    phen_file.write(f\"FID IID PL\\n\")\n",
    "\n",
    "    \n",
    "    for acc in acc_inte:\n",
    "        fid = 0\n",
    "        iid = acc\n",
    "        phenotype = str(target_df.loc[acc].values[0])\n",
    "        phen_file.write(f\"{fid} {iid} {phenotype}\\n\")\n",
    "\n",
    "print(\"ALL DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50e656-97f1-4dc9-b023-59e6592ccb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plink2 --vcf Chr07_6770001_6920000.vcf --pheno PL.txt --pheno-name PL  --glm allow-no-covars --adjust --out PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef3016-9cbb-4a64-9289-b903acf7ed66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2b100c-e321-4d95-af62-2a4decd702d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 position\n",
    "pl_adjust = pd.read_table(os.path.join(OUT_PATH, \"PL.PL.glm.linear.adjusted\"))\n",
    "top_snp_list = sorted(pl_adjust.head(10)[\"ID\"].to_list())\n",
    "\n",
    "# Read_file\n",
    "hap_count = pd.read_table(os.path.join(RES_PATH, \"Haplotype_Counts_Info.tsv\"), index_col=\"Haplotype_id\")\n",
    "hap_base = pd.read_table(os.path.join(RES_PATH, \"Haplotype_Basepair_Info.tsv\"), index_col=\"Haplotype_ID\")\n",
    "hap_score = pd.read_table(os.path.join(RES_PATH, \"Haplotype_Score_Info.tsv\"), index_col=\"Haplotype_ID\")\n",
    "hap_id_df = pd.read_table(os.path.join(RES_PATH, \"Genotype_by_Hap_ID.tsv\"), index_col=\"Region_index\")\n",
    "\n",
    "# 表型数据\n",
    "raw_phenos = pd.read_excel(os.path.join(RAW_PATH, \"Phenotypes for GWAS-upload public database.xlsx\"), index_col=\"Accessions\")\n",
    "raw_phenos = raw_phenos.drop(columns=\"ID\")\n",
    "raw_phenos = raw_phenos.replace({\"-\":np.nan})\n",
    "raw_phenos = raw_phenos.dropna(axis=0, how=\"all\")\n",
    "raw_phenos = raw_phenos.rename(columns={'HZ-Pod length':'HZ-PL', 'GZ-Pod length':'GZ-PL', \n",
    "                                        'HZ Pod Sugar content (mg/g)':'HZ-PSugar','GZ Pod Sugar content  (mg/g)':'GZ-PSugar', \n",
    "                                        'HZ Pod Starch content(mg/g)':'HZ-PStarch','GZ Pod Strach Content (mg/g)':'GZ-PStarch', \n",
    "                                        'HZ Pod Protein content(g/Kg)':'HZ-PProtein','GZ Pod protein  (g/Kg)':'GZ-PProtein', \n",
    "                                        'HZ Seed Sugar (mg/g)':'HZ-SSuger','GZ Seed Sugar (mg/g)':'GZ-SSuger', \n",
    "                                        'HZ Seed Starch (mg/g)':'HZ-SStarch','GZ Seed Starch (mg/g)':'GZ-SStarch', \n",
    "                                        'HZ Seed Protein (g/kg)':'HZ-SProtein','GZ Seed Protein (g/kg)':'GZ-SProtein', \n",
    "                                        'Pod shattering':'PS'})\n",
    "target_df = raw_phenos[\"HZ-PL\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1f7af2-5155-4fcd-9c21-af2f1ffacc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr, start, end = region_name.split(\"_\")\n",
    "\n",
    "hap_count_sel = hap_count[(hap_count[\"Chr\"]==chr)&(hap_count[\"Start\"]==int(start))&(hap_count[\"End\"]==int(end))].copy()\n",
    "hap_score_sel = hap_score.loc[hap_count_sel.index].copy()\n",
    "hap_score_sel = hap_score_sel[[\"Hap_Score.by_Total_pop\"]].copy()\n",
    "\n",
    "hap_count_score = pd.concat([hap_count_sel, hap_score_sel], axis=1)\n",
    "hap_count_score = hap_count_score.sort_values(by=[\"Hap_Score.by_Total_pop\", \"Genotyped_prop\"], ascending=[False, False])\n",
    "hap_count_score[\"Total\"] = hap_count_score['Genotyped_sample_num'].astype(str) + ' (' + (hap_count_score['Genotyped_prop'] * 100).round(2).astype(str) + '%)'\n",
    "hap_count_score[\"VC\"] = hap_count_score['VC_sample_num'].astype(str) + ' (' + (hap_count_score['VC_prop'] * 100).round(2).astype(str) + '%)'\n",
    "hap_count_score[\"VL\"] = hap_count_score['VL_sample_num'].astype(str) + ' (' + (hap_count_score['VL_prop'] * 100).round(2).astype(str) + '%)'\n",
    "hap_count_score[\"G\"] = hap_count_score['G_sample_num'].astype(str) + ' (' + (hap_count_score['G_prop'] * 100).round(2).astype(str) + '%)'\n",
    "hap_count_score = hap_count_score[['Haplotype_class', 'Hap_Score.by_Total_pop', 'Total', 'VC', 'VL', 'G']].copy()\n",
    "hap_count_score = hap_count_score.rename(columns={'Haplotype_class':\"Class\", 'Hap_Score.by_Total_pop':\"Score\"})\n",
    "\n",
    "# Add pehn value\n",
    "hap_id_sel = hap_id_df.loc[region_name]\n",
    "for index in hap_count_score.index:\n",
    "    hap_id_sample = hap_id_sel[hap_id_sel==index].index.to_list()\n",
    "    phen_val_list = target_df.loc[list(set(target_df.index).intersection(hap_id_sample))].values\n",
    "    if len(phen_val_list) > 1:\n",
    "        mean_value = round(np.mean(phen_val_list), 2)\n",
    "        sd_value = round(np.std(phen_val_list), 2)\n",
    "        hap_count_score.loc[index, \"PL\"] = \"{}  ± {}\".format(mean_value, sd_value)\n",
    "    elif len(phen_val_list) == 1:\n",
    "        hap_count_score.loc[index, \"PL\"] = round(phen_val_list[0], 2)\n",
    "    else:\n",
    "        hap_count_score.loc[index, \"PL\"] = \"NA\"\n",
    "\n",
    "# Add base\n",
    "for index in hap_count_score.index:\n",
    "    snp_pos = [int(x) for x in hap_base.loc[index, \"SNP_Pos\"].split(\",\")]\n",
    "    hap_base_list = hap_base.loc[index, \"Haplotype\"].split(\",\")\n",
    "    if len(snp_pos) != len(hap_base_list):\n",
    "        raise ValueError(\"snp_pos not equal hap_base_list\")\n",
    "\n",
    "    for x, y in zip(snp_pos, hap_base_list):\n",
    "        if x in top_snp_list:\n",
    "            hap_count_score.loc[index, x] = y\n",
    "\n",
    "hap_count_score = hap_count_score[['Class']+top_snp_list+['Total', 'VC', 'VL', 'G', 'Score', 'PL']]\n",
    "hap_count_score.to_excel(os.path.join(OUT_PATH, \"{}_PL.xlsx\".format(region_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8683e8-24ae-40aa-be0f-bc02a70dfddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbaa8907-b80f-40e0-948b-ac74139ac753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAAbCAYAAAD79PlqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAACS0lEQVR4nO3bPU4cQRAG0BrkYPmRCOwMk3ADTuCEa5D5DByCc5DDQRCXYXcHEbgdmEkmWku9U73b70mtyaarP1VLlHYYSiklAAAAKjrJLgAAADg+Bg0AAKA6gwYAAFCdQQMAAKjOoAEAAFRn0AAAAKozaAAAANUZNAAAgOoMGhHx+hoxDBFvb9mV7Fcv51ySTGnB1IdPT332o3uYp6XsM2uZ791SLpDJoBER7+/ZFSyjl3MuSaa0YOrDzSa3jizuYZ6Wss+sZb53S7lApm/ZBfyPUkpst9vq7x3Hk4g4jXEcY7P5U/39rejlnEuSKS2Y+vDz8yMiVt31o3uYp6XsM2uZ791SLhyfs7OzGIYhu4zdlAOyXq9LROxh/SoRpUTc7un9raxezilTq7c19eHvr2dv/egeyj67lvneLeViHdtar9fZf5LvzKdTERHx/ev5I7WK/evlnEuSKS2Y+vDn17O3fnQP87SUfWYt871bygXyDKWUkl3ErsqePp16fj6J+/vTeHkZ4+7ueH/i7OWcS5IpLZj68OHhIx4fV931o3uYp6XsM2uZ791SLhyfQ/p06qD+R2MYhjg/P6/+3qurf8/r69PYw+ub0cs5lyRTWjD14c3NKiL660f3ME9L2WfWMt+7pVwgk0+nAACA6gwaEXF5mV3BMno555JkSgumPry4yK0ji3uYp6XsM2uZ791SLpDpoP5HAwAAOAx+0QAAAKozaAAAANUZNAAAgOoMGgAAQHUGDQAAoDqDBgAAUJ1BAwAAqM6gAQAAVPcXT+b8gZ+tlqYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x10 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chromosome, start_position, end_position = region_name.split(\"_\")\n",
    "start_position = int(start_position)\n",
    "end_position = int(end_position)\n",
    "snp_positions = top_snp_list\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 0.1))\n",
    "\n",
    "# Plot the genome region as a line\n",
    "plt.plot([start_position, end_position], [1, 1], color='black')\n",
    "\n",
    "# Plot the SNP positions as vertical bars\n",
    "for snp in snp_positions:\n",
    "    plt.plot([snp, snp], [0.99, 1.01], color='blue', marker='|', linewidth=0.1)\n",
    "\n",
    "# Annotate the plot\n",
    "#plt.title(f'Chromosome {chromosome}: Positions {start_position}-{end_position}')\n",
    "#plt.xlabel('Position')\n",
    "\n",
    "# Remove the y-axis\n",
    "plt.yticks([])\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# Remove the top and right spines (border lines)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "#plt.gca().spines['bottom'].set_position(('outward', 10))\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(OUT_PATH, \"{}_PL.pdf\".format(region_name)), format='pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad579bc-44ea-44c0-8889-ed27b104777d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
